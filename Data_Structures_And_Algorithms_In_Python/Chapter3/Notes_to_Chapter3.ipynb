{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df219c90",
   "metadata": {},
   "source": [
    "# Algorithm Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c736eb",
   "metadata": {},
   "source": [
    "## 3.1 Experimental Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3a972",
   "metadata": {},
   "source": [
    "    simply put: \n",
    "    Data Structure - is a systematic way of organizing and accessing data \n",
    "    Algorithm - step by step procedure for performing some task in a finite amount of time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae8918",
   "metadata": {},
   "source": [
    "Challenges of Experimental Analysis: (experimental analysis is valuable especially when fine-tuning production quality code -> still there are 3 major limitations)\n",
    "\n",
    "    1. Experimental running times of two algorithms are difficult to directly compare unless the experiments are performed in the same hardware and software environments\n",
    "    2. Expirements can be done only on limited set of test inputs; hence leaving out the running time of inputs not included -> naturally, these inputs can be important\n",
    "    3. An algorithm must be fully implemented in order to execute it to study its running time experimentally\n",
    "    \n",
    "   this last requirement is the most serious drawback to the use of experimental studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65683c9d",
   "metadata": {},
   "source": [
    "### Moving beyond experimental analysis\n",
    "The goal is to develop an approach to analyzing the efficiency of algorithms that:\n",
    "    1. allows us to evaluate relative efficiency of any two algorithms in a way that is independent of the hardware and software environment.\n",
    "    2. Is performed by studying a high-level description of the algorithm without need for implementation. \n",
    "    3. Takes into account all possible inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7b6e15",
   "metadata": {},
   "source": [
    "### Counting Primitive Operations\n",
    "\n",
    "    To analyze the running time of an algorithm without performing experiments, we perform analysis directly on high-level description of the algorithm. We define a set of \"primitive operations\" such as the following:\n",
    "    - Assigning an identifier to an object \n",
    "    - Determining the object associated with identifier (name resolution)\n",
    "    - Performing an arthmetic operation\n",
    "    - Comparing two numbers\n",
    "    - Accessing a single element of a Python list by index\n",
    "    - Calling a function \n",
    "    - Returning from a function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288fd7ae",
   "metadata": {},
   "source": [
    "Measuring operations as a function of input size\n",
    "\n",
    "To capture the order of growth of an algorithm's running time, we will associate, with each algorithm, a function f(n) that characterized the number of primitive operations that are performed as a function of the input size n. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cb5b69",
   "metadata": {},
   "source": [
    "### Focusing on the Worst Case Input\n",
    "An algorithm may run faster on some inputs than it does on others of the same size. Thus, we may wish to express this running time as a average case. Unfortunately, it is quite challening. An average-case analysis usually requires that we calculate expected running times based on a given input distribution, which usually involves sophisticated probability theory.\n",
    "\n",
    "    THEREFORE, for the remainder of this book (unless specified otherwise), we will characterize running times in terms of the worst-case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2c8940",
   "metadata": {},
   "source": [
    "Making the standard of success for an algorithm to perform well in the worst case necessarily requires that it will do well on every input. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9b8530",
   "metadata": {},
   "source": [
    "# The Seven Functions used in this book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd76649",
   "metadata": {},
   "source": [
    "### The Constant Function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4879a",
   "metadata": {},
   "source": [
    "Probably the simplest one to think of. This is the function: f(n) = c, for some fixed constant c such as c = 5 or c = 27 or c = 2^10. That is, for any argument n, the constant function f(n) assigns the value c. In other words, it does not matter what the value of n is, f(n) will always be equal to constant c. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9b58a1",
   "metadata": {},
   "source": [
    "Because we are mostly interested in integer functions, the most fundamental constant function is g(n) = 1, and this is typical constant function used in this book. Note that any other constant function, f(n) = c, can be written as a constant c times g(n). That is, f(n) = cg(n). As simple as it is, the constant function is very useful because it characterizes the number of steps needed to do a basic operating on a computer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e996b42",
   "metadata": {},
   "source": [
    "### The Logarithm Function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456be945",
   "metadata": {},
   "source": [
    "Logarithmic function: $f(n) = \\log_b{n}$, for some constant b > 1. This function is defined as follows $x = log_b{n}$ if an only if $b^x = {n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa13b204",
   "metadata": {},
   "source": [
    "By definition, $log_b{1} = 0$. The value b is known as a base of the logarithm. The most popular base for the logarithm function in computer science is 2, as computers store integers in binary, and because a common operation in many algorithms is to repeatedly divide input in half. It is so common that we will even omit it from the notation $log{n} = log_2{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cbc0e0",
   "metadata": {},
   "source": [
    "The following proposition describes several important identities that involve logarithms for any base greater than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb9c79",
   "metadata": {},
   "source": [
    "### Logarithm Rules:\n",
    "Given real numbers a > 0, b > 1, c > 0 and d > 1, we have:\n",
    "1. $log_b{ac} = log_b{a} + log_b{c}$ \n",
    "2. $log_b{a/c} = log_b{a} - log_b{c}$\n",
    "3. $log_b{a^c} = {c}log_b{a}$\n",
    "4. $log_b{a} = log_d{a}/log_d{b}$\n",
    "5. $b^(log_d{a}) = a^(log_d{b})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53860421",
   "metadata": {},
   "source": [
    "### The Linear Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e728c47",
   "metadata": {},
   "source": [
    "Another simple yet important is the linear funcion $$f(n) = n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6660b22f",
   "metadata": {},
   "source": [
    "given an input value n, the linear function f assigns the value n itselt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e24064",
   "metadata": {},
   "source": [
    "The LINEAR FUNCTION arises in algorithm analysis any time we have to do a simple basic operation for each of n elements. For example comparing element x to every element of a sequence of size n will require n comparisons. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19a798",
   "metadata": {},
   "source": [
    "### The linear function represents the best running time we can hope to achieve for any algorithm that processes each of n objects that are not already in the computers memory, because reading in the n objects, already requires n operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024f1c5",
   "metadata": {},
   "source": [
    "### The N-Log-N Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c7adc",
   "metadata": {},
   "source": [
    "The next function discussed is N-Log-N Function: $$f(n) = {n}log{n}$$, that is the function that assigns to an input n the value of n times the logarithm base-two of n. This function grows a little more rapidly than the linear function and a lot less rapidly than quadratic function; therefore we would greatly prefer an algorithm with a running time that is proportional to nlogn than quadratic function. We will see several algos that exibit nlogn running time. For example, the fastest possible algo for sorting n arbitrary (przypadkowe) values require time proportional to nlogn. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ce8f7f",
   "metadata": {},
   "source": [
    "### The Quadratic Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6244ae",
   "metadata": {},
   "source": [
    "Another function that appers often in algorithms is: $$f(n) = n^2,$$ that is, given input n, the function assigns the product of n with itself - squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce5a3a",
   "metadata": {},
   "source": [
    "The main reason why the quadratic function appears in the analysis of algorithms is that there are many algorithms that have nested loops, where the inner loop performs a linear number of operations and the outer loop is performed a linear number of times. Thus, in such cases, the algorithm performs $n * n = n^2$ operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d93a60c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
